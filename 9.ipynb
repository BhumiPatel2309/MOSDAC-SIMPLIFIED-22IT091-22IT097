{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vgs5Iq-N5THR",
        "outputId": "54bcd82b-ae4d-4583-88bd-b52a068f5c17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m119.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.5/310.5 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip -q install langchain langchain-community langchain-text-splitters\n",
        "!pip -q install faiss-cpu sentence-transformers pypdf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, numpy as np\n",
        "from typing import List, Dict, Any\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.embeddings.base import Embeddings\n",
        "from langchain.schema import Document"
      ],
      "metadata": {
        "id": "HlKhxGKo6CLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PDF_PATH = \"/content/MOSDAC.pdf\"\n",
        "assert os.path.exists(PDF_PATH),"
      ],
      "metadata": {
        "id": "Jmzq7CyP6Zpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = PyPDFLoader(PDF_PATH)\n",
        "pages: List[Document] = loader.load()\n",
        "print(\"Pages:\", len(pages))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NCQs3qn6gNr",
        "outputId": "a3988e0f-29b6-4ea1-b01a-b2ae80d9c197"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pages: 95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=500,\n",
        "    chunk_overlap=100\n",
        ")\n",
        "docs = splitter.split_documents(pages)\n",
        "print(\"Chunks:\", len(docs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufgJubX36icx",
        "outputId": "fb173fde-8095-4a15-a641-fc5289d859af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunks: 397\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "st_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "id": "ANrATRol6kRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class STEmbeddings(Embeddings):\n",
        "    def __init__(self, mdl): self.mdl = mdl\n",
        "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
        "        return self.mdl.encode(texts, batch_size=64, normalize_embeddings=True).tolist()\n",
        "    def embed_query(self, text: str) -> List[float]:\n",
        "        return self.mdl.encode([text], normalize_embeddings=True).tolist()[0]\n",
        "\n",
        "emb = STEmbeddings(st_model)"
      ],
      "metadata": {
        "id": "vCN4NcWn6msZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vs = FAISS.from_documents(docs, emb)\n",
        "vs.save_local(\"mosdac_faiss\")\n",
        "print(\"✅ FAISS saved at mosdac_faiss\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1mMXvIy6qCP",
        "outputId": "07a836ad-70b5-44ac-bbf4-a9b240a7edc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ FAISS saved at mosdac_faiss\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def split_sentences(text: str) -> List[str]:\n",
        "    s = re.split(r'(?<=[.!?])\\s+', text.strip())\n",
        "    # clean and filter very short/noisy\n",
        "    return [t.strip() for t in s if len(t.strip()) > 15]\n",
        "\n",
        "def retrieve_chunks(query: str, k: int = 6) -> List[Document]:\n",
        "    return vs.similarity_search(query, k=k)\n",
        "\n",
        "def pick_best_sentence(query: str, contexts: List[str]) -> str:\n",
        "    # Embed query and candidate sentences, pick highest cosine sim\n",
        "    q_emb = st_model.encode([query], normalize_embeddings=True)\n",
        "    s_emb = st_model.encode(contexts, normalize_embeddings=True)\n",
        "    sims = util.cos_sim(q_emb, s_emb).cpu().numpy()[0]\n",
        "    best_idx = int(np.argmax(sims))\n",
        "    return contexts[best_idx]\n",
        "\n",
        "def rag_answer(query: str, k: int = 6) -> Dict[str, Any]:\n",
        "    retrieved = retrieve_chunks(query, k=k)\n",
        "    all_sents = []\n",
        "    citations = []\n",
        "    for i, d in enumerate(retrieved, 1):\n",
        "        sents = split_sentences(d.page_content)\n",
        "        for s in sents:\n",
        "            all_sents.append((s, i, d.metadata.get(\"page\")))\n",
        "    if not all_sents:\n",
        "        return {\"answer\":\"I couldn't find this in the PDF.\", \"citations\":[]}\n",
        "\n",
        "    best_sent = pick_best_sentence(query, [s for s,_,_ in all_sents])\n",
        "    # find its citation tuple\n",
        "    for s, ci, pg in all_sents:\n",
        "        if s == best_sent:\n",
        "            citations.append({\"chunk_rank\": ci, \"page\": pg})\n",
        "            break\n",
        "    return {\"answer\": best_sent, \"citations\": citations, \"retrieved\": len(retrieved)}"
      ],
      "metadata": {
        "id": "L_4lmEgU-5WP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import numpy as np\n",
        "\n",
        "# Use strong embedding model for semantic similarity\n",
        "sim_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "EVAL_SET = [\n",
        "    {\n",
        "        \"q\": \"What is INSAT-3DR?\",\n",
        "        \"reference\": \"INSAT-3DR is an advanced meteorological satellite that incorporates an imager, a sounder, a data relay transponder, and a satellite aided search and rescue payload.\"\n",
        "    },\n",
        "    {\n",
        "        \"q\": \"What are the payloads on INSAT-3DR?\",\n",
        "        \"reference\": \"The payloads on INSAT-3DR are the Imager, the Sounder, the Data Relay Transponder (DRT), and the Satellite Aided Search and Rescue (SAS&R) payloads.\"\n",
        "    },\n",
        "    {\n",
        "        \"q\": \"What are the objectives of SARAL-AltiKa\",\n",
        "        \"reference\": \"SARAL/AltiKa main scientific objective is to provide data products to oceanographic research user community in studies leading to improve our knowledge of the ocean meso-scale variability\"\n",
        "    },\n",
        "    {\n",
        "        \"q\": \"Explain Megha Tropiques\",\n",
        "        \"reference\": \"Megha-Tropiques is an Indo-French Joint Satellite Mission for studying the water cycle and energy exchanges in the tropics.\"\n",
        "    },\n",
        "    {\n",
        "        \"q\": \"What is Kalpana-1?\",\n",
        "        \"reference\": \"Kalpana-1 is the first dedicated meteorological satellite launched by Indian Space Research Organisation using Polar Satellite Launch Vehicle on 2002-09-12.\"\n",
        "    },\n",
        "    {\n",
        "        \"q\": \"Give INSAT-3DS Introduction\",\n",
        "        \"reference\": \"INSAT-3DS is a dedicated meteorological spacecraft designed for enhanced meteorological observation and monitoring of land and ocean surfaces of weather forecasting and disaster warning.\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# --- Semantic similarity scoring ---\n",
        "def semantic_score(ref, pred):\n",
        "    emb1 = sim_model.encode(ref, convert_to_tensor=True)\n",
        "    emb2 = sim_model.encode(pred, convert_to_tensor=True)\n",
        "    return util.cos_sim(emb1, emb2).item()\n",
        "\n",
        "scores = []\n",
        "for item in EVAL_SET:\n",
        "    q, ref = item[\"q\"], item[\"reference\"]\n",
        "    pred = rag_answer(q)[\"answer\"]   # <-- bot prediction\n",
        "    score = semantic_score(ref, pred)\n",
        "    scores.append(score)\n",
        "    print(f\"\\nQ: {q}\")\n",
        "    print(f\"Reference: {ref}\")\n",
        "    print(f\"Predicted: {pred}\")\n",
        "    print(f\"Semantic Similarity: {score:.2f}\")\n",
        "\n",
        "avg_score = np.mean(scores)\n",
        "print(\"Final Semantic Evaluation:\")\n",
        "print(f\"Average Similarity Score: {avg_score:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJzBS4eS_uye",
        "outputId": "188a3166-d112-467d-defd-7235ac481e75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Q: What is INSAT-3DR?\n",
            "Reference: INSAT-3DR is an advanced meteorological satellite that incorporates an imager, a sounder, a data relay transponder, and a satellite aided search and rescue payload.\n",
            "Predicted: INSAT -3DR is a multipurpose geosynchronous spacecraft with main \n",
            "meteorological payloads (imager and sounder).\n",
            "Semantic Similarity: 0.93\n",
            "\n",
            "Q: What are the payloads on INSAT-3DR?\n",
            "Reference: The payloads on INSAT-3DR are the Imager, the Sounder, the Data Relay Transponder (DRT), and the Satellite Aided Search and Rescue (SAS&R) payloads.\n",
            "Predicted: INSAT-3D Payloads \n",
            "The satellite has 3 payloads: \n",
            "● Meteorological (MET) - IMAGER and SOUNDER \n",
            "● Data Relay Transponder (DRT) \n",
            "● Satellite Aided Search and Rescue (SAS&R) \n",
            "Meteorological Payload \n",
            "The INSAT-3D spacecraft incorporates advanced Imager and Sounder instruments.\n",
            "Semantic Similarity: 0.89\n",
            "\n",
            "Q: What are the objectives of SARAL-AltiKa\n",
            "Reference: SARAL/AltiKa main scientific objective is to provide data products to oceanographic research user community in studies leading to improve our knowledge of the ocean meso-scale variability\n",
            "Predicted: SARAL/AltiKa mission belongs to the global altimetry system and then participates to the \n",
            "precise and accurate observations of ocean circulation and sea surface elevation for its life \n",
            "time.\n",
            "Semantic Similarity: 0.70\n",
            "\n",
            "Q: Explain Megha Tropiques\n",
            "Reference: Megha-Tropiques is an Indo-French Joint Satellite Mission for studying the water cycle and energy exchanges in the tropics.\n",
            "Predicted: Megha Tropiques \n",
            "Megha-Tropiques is an Indo-French Joint Satellite Mission for studying the water cycle and \n",
            "energy exchanges in the tropics.\n",
            "Semantic Similarity: 0.99\n",
            "\n",
            "Q: What is Kalpana-1?\n",
            "Reference: Kalpana-1 is the first dedicated meteorological satellite launched by Indian Space Research Organisation using Polar Satellite Launch Vehicle on 2002-09-12.\n",
            "Predicted: KALPANA-1 Introduction \n",
            "Kalpana-1 is the first dedicated meteorological satellite launched by Indian Space Research \n",
            "Organisation using Polar Satellite Launch Vehicle on 2002-09-12.\n",
            "Semantic Similarity: 0.99\n",
            "\n",
            "Q: Give INSAT-3DS Introduction\n",
            "Reference: INSAT-3DS is a dedicated meteorological spacecraft designed for enhanced meteorological observation and monitoring of land and ocean surfaces of weather forecasting and disaster warning.\n",
            "Predicted: INSAT -3DS is a multipurpose \n",
            "geosynchronous spacecraft with main meteorological payloads ( imager and sounder).\n",
            "Semantic Similarity: 0.91\n",
            "Final Semantic Evaluation:\n",
            "Average Similarity Score: 0.90\n"
          ]
        }
      ]
    }
  ]
}